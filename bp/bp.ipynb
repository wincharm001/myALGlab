{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读取数据集\n",
    "iris_data = pd.read_csv('D:\\\\Users\\\\my_projects\\\\vscode_projects\\\\deep_learning\\\\datasets/iris.data')\n",
    "display(iris_data.head())\n",
    "# adm_data = pd.read_csv('../adm_data.csv')\n",
    "# display(adm_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理：将样本标签进行编码，并将数据集分为训练集和测试集\n",
    "le = LabelEncoder()\n",
    "le.fit(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "iris_data['class'] = le.transform(iris_data['class'])\n",
    "\n",
    "features = iris_data.columns.to_list()\n",
    "features.remove('class')\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris_data[features], iris_data['class'],\n",
    "                                                    test_size=0.2, shuffle=True, random_state=2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = adm_data.columns.to_list()\n",
    "\n",
    "train_x2, test_x2, train_y2, test_y2 = train_test_split(adm_data[features_2[1: -1]], adm_data[features_2[-1]],\n",
    "                                                    test_size=0.2, shuffle=True, random_state=2023)\n",
    "\n",
    "train_x2_np, test_x2_np = np.array(train_x2, dtype=np.float32), np.array(test_x2, dtype=np.float32)\n",
    "train_y2_np, test_y2_np = np.array(train_y2, dtype=np.float32), np.array(test_y2, dtype=np.float32)\n",
    "\n",
    "train_x2_t, test_x2_t = torch.from_numpy(train_x2_np), torch.from_numpy(test_x2_np)\n",
    "train_y2_t, test_y2_t = torch.from_numpy(train_y2_np), torch.from_numpy(test_y2_np)\n",
    "\n",
    "trainset2 = TensorDataset(train_x2_t, train_y2_t)\n",
    "testset2 = TensorDataset(test_x2_t, test_y2_t)\n",
    "\n",
    "trainloader2 = DataLoader(trainset2, batch_size=2, shuffle=False)\n",
    "testloader2 = DataLoader(testset2, batch_size=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_np, test_x_np, train_y_np, test_y_np = np.array(train_x, dtype=np.float32), np.array(test_x, dtype=np.float32), np.array(train_y, dtype=np.float32), np.array(test_y, dtype=np.float32)\n",
    "\n",
    "train_x_t, test_x_t = torch.from_numpy(train_x_np), torch.from_numpy(test_x_np)\n",
    "train_y_t, test_y_t = torch.from_numpy(train_y_np), torch.from_numpy(test_y_np)\n",
    "\n",
    "trainset = TensorDataset(train_x_t, train_y_t)\n",
    "testset = TensorDataset(test_x_t, test_y_t)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x):\n",
    "    y = np.zeros(3)\n",
    "    y[int(x)] = 1\n",
    "    return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class torchBP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dims, hidden_dims)\n",
    "        self.fc2 = nn.Linear(hidden_dims, output_dims)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = nn.functional.relu(self.fc1(x))\n",
    "        output = self.fc2(output)\n",
    "        # output = nn.functional.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class npBP():\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims) -> None:\n",
    "        self.ids = input_dims\n",
    "        self.hds = hidden_dims\n",
    "        self.ods = output_dims\n",
    "\n",
    "        self.w1 = np.random.randn(self.ids, self.hds) * 0.001\n",
    "        self.b1 = np.zeros(self.hds)\n",
    "        self.w2 = np.random.randn(self.hds, self.ods) * 0.001\n",
    "        self.b2 = np.zeros(self.ods)\n",
    "\n",
    "\n",
    "    def f(self, x):\n",
    "        # RELU\n",
    "        return np.where(x > 0, x, 0)\n",
    "    \n",
    "    def df(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = self.f(self.z1)\n",
    "        self.a1 = self.a1.reshape(1, -1)\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = self.z2\n",
    "\n",
    "        return self.a2\n",
    "    \n",
    "\n",
    "    def back_propagation(self, x, y, y_hat, lr):\n",
    "        dE_da2 = y_hat - y\n",
    "        dE_dz2 = dE_da2 * self.df(self.z2)\n",
    "        dE_dw2 = dE_dz2 * self.a1.T\n",
    "        dE_db2 = dE_dz2.reshape(-1)\n",
    "        \n",
    "        dE_dz1 = np.dot(self.w2, dE_dz2.T).T * self.df(self.z1)\n",
    "        dE_dw1 = np.dot(x.reshape(-1, 1), dE_dz1)\n",
    "        dE_db1 = dE_dz1.reshape(-1)\n",
    "\n",
    "\n",
    "        self.w1 -= lr * dE_dw1\n",
    "        self.b1 -= lr * dE_db1\n",
    "        self.w2 -= lr * dE_dw2\n",
    "        self.b2 -= lr * dE_db2\n",
    "\n",
    "\n",
    "    def train(self, X, y, epochs, lr):\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0.\n",
    "            for x, target in zip(X, y):\n",
    "                y_hat = self.forward(x)\n",
    "                y_hat = y_hat.item()\n",
    "                self.back_propagation(x, target, y_hat, lr)\n",
    "                train_loss += y_hat - target\n",
    "            \n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                train_loss = np.sum(np.abs(train_loss)) / len(X)\n",
    "                print(f'Epoch {epoch + 1}\\ttrain loss: {train_loss:.4f}')\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = self.forward(X)\n",
    "        return pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttbp = torchBP(7, 128, 1)\n",
    "lr, epochs = 0.00001, 250\n",
    "optimizer = torch.optim.Adam(ttbp.parameters(), lr=lr)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.\n",
    "        for x, y in trainloader2:\n",
    "            optimizer.zero_grad()\n",
    "            output = ttbp(x)\n",
    "            loss = loss_func(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            train_loss /= len(trainloader2.dataset)\n",
    "            print(f'Epoch {epoch + 1}\\ttrain loss: {train_loss:.4f}')\n",
    "\n",
    "\n",
    "def test():\n",
    "    c = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader2:\n",
    "            output = ttbp(x)\n",
    "\n",
    "            if c <= 9:\n",
    "                print(f'sample {c}\\nlabel: {y}\\tthe prediction is {output}\\n')\n",
    "                c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\ttrain loss: 0.0096\n",
      "Epoch 100\ttrain loss: 0.0091\n",
      "Epoch 150\ttrain loss: 0.0091\n",
      "Epoch 200\ttrain loss: 0.0090\n",
      "Epoch 250\ttrain loss: 0.0090\n",
      "sample 0\n",
      "label: tensor([0.9300])\tthe prediction is tensor([[0.7694]])\n",
      "\n",
      "sample 1\n",
      "label: tensor([0.7200])\tthe prediction is tensor([[0.7365]])\n",
      "\n",
      "sample 2\n",
      "label: tensor([0.5700])\tthe prediction is tensor([[0.6722]])\n",
      "\n",
      "sample 3\n",
      "label: tensor([0.6200])\tthe prediction is tensor([[0.7370]])\n",
      "\n",
      "sample 4\n",
      "label: tensor([0.6700])\tthe prediction is tensor([[0.6351]])\n",
      "\n",
      "sample 5\n",
      "label: tensor([0.6400])\tthe prediction is tensor([[0.6800]])\n",
      "\n",
      "sample 6\n",
      "label: tensor([0.7100])\tthe prediction is tensor([[0.6560]])\n",
      "\n",
      "sample 7\n",
      "label: tensor([0.7100])\tthe prediction is tensor([[0.7119]])\n",
      "\n",
      "sample 8\n",
      "label: tensor([0.5400])\tthe prediction is tensor([[0.7065]])\n",
      "\n",
      "sample 9\n",
      "label: tensor([0.6900])\tthe prediction is tensor([[0.6816]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\ttrain loss: 0.0009\n",
      "Epoch 100\ttrain loss: 0.0009\n",
      "Epoch 150\ttrain loss: 0.0008\n",
      "Epoch 200\ttrain loss: 0.0007\n",
      "Epoch 250\ttrain loss: 0.0006\n",
      "sample 0\n",
      "label: 0.9300\tthe prediction is [0.79307572]\n",
      "\n",
      "sample 1\n",
      "label: 0.7200\tthe prediction is [0.71767747]\n",
      "\n",
      "sample 2\n",
      "label: 0.5700\tthe prediction is [0.71138987]\n",
      "\n",
      "sample 3\n",
      "label: 0.6200\tthe prediction is [0.73888324]\n",
      "\n",
      "sample 4\n",
      "label: 0.6700\tthe prediction is [0.63814836]\n",
      "\n",
      "sample 5\n",
      "label: 0.6400\tthe prediction is [0.67890214]\n",
      "\n",
      "sample 6\n",
      "label: 0.7100\tthe prediction is [0.68573848]\n",
      "\n",
      "sample 7\n",
      "label: 0.7100\tthe prediction is [0.67258561]\n",
      "\n",
      "sample 8\n",
      "label: 0.5400\tthe prediction is [0.67625791]\n",
      "\n",
      "sample 9\n",
      "label: 0.6900\tthe prediction is [0.7092448]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbp = npBP(7, 128, 1)\n",
    "nbp.train(train_x2_np, train_y2_np, 250, 0.001)\n",
    "c = 0\n",
    "for x, y in zip(test_x2_np, test_y2_np):\n",
    "    pred = nbp.predict(x)\n",
    "    # 查看 10 个样本的具体输出\n",
    "    if c <= 9:\n",
    "        print(f'sample {c}\\nlabel: {y:.4f}\\tthe prediction is {pred[0]}\\n')\n",
    "        c += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "features: [6.4 2.8 5.6 2.1]\tlabel: 2.0\tthe prediction is [[2.]]\n",
      "\n",
      "sample 1\n",
      "features: [6.4 2.9 4.3 1.3]\tlabel: 1.0\tthe prediction is [[1.]]\n",
      "\n",
      "sample 2\n",
      "features: [5.7 2.8 4.1 1.3]\tlabel: 1.0\tthe prediction is [[1.]]\n",
      "\n",
      "sample 3\n",
      "features: [7.3 2.9 6.3 1.8]\tlabel: 2.0\tthe prediction is [[2.]]\n",
      "\n",
      "sample 4\n",
      "features: [6.8 2.8 4.8 1.4]\tlabel: 1.0\tthe prediction is [[1.]]\n",
      "\n",
      "sample 5\n",
      "features: [5.7 2.5 5.  2. ]\tlabel: 2.0\tthe prediction is [[2.]]\n",
      "\n",
      "sample 6\n",
      "features: [5.4 3.  4.5 1.5]\tlabel: 1.0\tthe prediction is [[1.]]\n",
      "\n",
      "sample 7\n",
      "features: [5.7 2.9 4.2 1.3]\tlabel: 1.0\tthe prediction is [[1.]]\n",
      "\n",
      "sample 8\n",
      "features: [5.  3.6 1.4 0.2]\tlabel: 0.0\tthe prediction is [[0.]]\n",
      "\n",
      "sample 9\n",
      "features: [6.  2.2 4.  1. ]\tlabel: 1.0\tthe prediction is [[1.]]\n",
      "\n",
      "the accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "nbp = npBP(4, 128, 1)\n",
    "nbp.train(train_x_np, train_y_np, 100, 0.01)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "c = 0\n",
    "for x, y in zip(test_x_np, test_y_np):\n",
    "    pred = np.round(nbp.predict(x))\n",
    "    if pred == y:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    # 查看 10 个样本的具体输出\n",
    "    if c <= 9:\n",
    "        print(f'sample {c}\\nfeatures: {x}\\tlabel: {y}\\tthe prediction is {pred}\\n')\n",
    "        c += 1\n",
    "\n",
    "print(f'the accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, epochs = 0.01, 100\n",
    "tbp = torchBP(4, 32, 3)\n",
    "optimizer = torch.optim.SGD(tbp.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = tbp(x)\n",
    "            y = y.long()\n",
    "            loss = loss_func(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            train_loss /= len(trainloader.dataset)\n",
    "            print(f'Epoch {epoch + 1}\\ttrain loss: {train_loss:.4f}')\n",
    "        \n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    c = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            output = tbp(x)\n",
    "            output = torch.argmax(output)\n",
    "            correct += (output == y).sum().item()\n",
    "            total += len(x)\n",
    "            if c <= 9:\n",
    "                print(f'sample {c}\\nfeatures: {x}\\tlabel: {y}\\tthe prediction is {output}\\n')\n",
    "                c += 1\n",
    "        \n",
    "    print(f'the accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\ttrain loss: 0.2661\n",
      "Epoch 20\ttrain loss: 0.2017\n",
      "Epoch 30\ttrain loss: 0.1778\n",
      "Epoch 40\ttrain loss: 0.1648\n",
      "Epoch 50\ttrain loss: 0.1568\n",
      "Epoch 60\ttrain loss: 0.1509\n",
      "Epoch 70\ttrain loss: 0.1462\n",
      "Epoch 80\ttrain loss: 0.1420\n",
      "Epoch 90\ttrain loss: 0.1385\n",
      "Epoch 100\ttrain loss: 0.1353\n",
      "sample 0\n",
      "features: tensor([[6.4000, 2.8000, 5.6000, 2.1000]])\tlabel: tensor([2.])\tthe prediction is 2\n",
      "\n",
      "sample 1\n",
      "features: tensor([[6.4000, 2.9000, 4.3000, 1.3000]])\tlabel: tensor([1.])\tthe prediction is 1\n",
      "\n",
      "sample 2\n",
      "features: tensor([[5.7000, 2.8000, 4.1000, 1.3000]])\tlabel: tensor([1.])\tthe prediction is 1\n",
      "\n",
      "sample 3\n",
      "features: tensor([[7.3000, 2.9000, 6.3000, 1.8000]])\tlabel: tensor([2.])\tthe prediction is 2\n",
      "\n",
      "sample 4\n",
      "features: tensor([[6.8000, 2.8000, 4.8000, 1.4000]])\tlabel: tensor([1.])\tthe prediction is 1\n",
      "\n",
      "sample 5\n",
      "features: tensor([[5.7000, 2.5000, 5.0000, 2.0000]])\tlabel: tensor([2.])\tthe prediction is 2\n",
      "\n",
      "sample 6\n",
      "features: tensor([[5.4000, 3.0000, 4.5000, 1.5000]])\tlabel: tensor([1.])\tthe prediction is 1\n",
      "\n",
      "sample 7\n",
      "features: tensor([[5.7000, 2.9000, 4.2000, 1.3000]])\tlabel: tensor([1.])\tthe prediction is 1\n",
      "\n",
      "sample 8\n",
      "features: tensor([[5.0000, 3.6000, 1.4000, 0.2000]])\tlabel: tensor([0.])\tthe prediction is 0\n",
      "\n",
      "sample 9\n",
      "features: tensor([[6.0000, 2.2000, 4.0000, 1.0000]])\tlabel: tensor([1.])\tthe prediction is 1\n",
      "\n",
      "the accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
